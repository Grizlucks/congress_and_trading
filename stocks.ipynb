{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Trades by Members of the US House of Representatives\n",
    "\n",
    "This project uses public data about the stock trades made by members of the US House of Representatives. This data is collected and maintained by Timothy Carambat as part of the [House Stock Watcher](https://housestockwatcher.com/) project. The project describes itself as follows:\n",
    "\n",
    "> With recent and ongoing investigations of incumbent congressional members being investigated for potentially violating the STOCK act. This website compiles this publicly available information in a format that is easier to digest then the original PDF source.\n",
    ">\n",
    "> Members of Congress must report periodic reports of their asset transactions. This website is purely for an informative purpose and aid in transparency.\n",
    ">\n",
    "> This site does not manipluate or censor any of the information from the original source. All data is transcribed by our community of contributors, which you can join for free by going to our transcription tool. Our moderation team takes great care in ensuring the accuracy of the information.\n",
    ">\n",
    "> This site is built and maintained by Timothy Carambat and supported with our contributors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some interesting questions to consider for this data set include:\n",
    "\n",
    "- Is there a difference in stock trading behavior between political parties? For example:\n",
    "    - does one party trade more often?\n",
    "    - does one party make larger trades?\n",
    "    - do the two parties invest in different stocks or sectors? For instance, do Democrats invest in Tesla more than Republicans?\n",
    "- What congresspeople have made the most trades?\n",
    "- What companies are most traded by congresspeople?\n",
    "- Is there evidence of insider trading? For example, Boeing stock dropped sharply in February 2020. Were there a suspiciously-high number of sales of Boeing before the drop?\n",
    "- When are stocks bought and sold? Is there a day of the week that is most common? Or a month of the year?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Data\n",
    "\n",
    "The full data set of stock trade disclosures is available as a CSV or as JSON at https://housestockwatcher.com/api.\n",
    "\n",
    "This data set does not, however, contain the political affiliation of the congresspeople. If you wish to investigate a question that relies on having this information, you'll need to find another dataset that contains it and perform a merge. *Hint*: Kaggle is a useful source of data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Cleaning and EDA\n",
    "\n",
    "- Clean the data.\n",
    "    - Certain fields have \"missing\" data that isn't labeled as missing. For example, there are fields with the value \"--.\" Do some exploration to find those values and convert them to null values.\n",
    "    - You may also want to clean up the date columns to enable time-series exploration.\n",
    "- Understand the data in ways relevant to your question using univariate and bivariate analysis of the data as well as aggregations.\n",
    "\n",
    "\n",
    "### Assessment of Missingness\n",
    "\n",
    "- Assess the missingness per the requirements in `project03.ipynb`\n",
    "\n",
    "### Hypothesis Test / Permutation Test\n",
    "Find a hypothesis test or permutation test to perform. You can use the questions at the top of the notebook for inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Findings\n",
    "\n",
    "### Introduction\n",
    "TODO\n",
    "\n",
    "### Cleaning and EDA\n",
    "TODO\n",
    "\n",
    "### Assessment of Missingness\n",
    "TODO\n",
    "\n",
    "### Hypothesis Test\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.652554Z",
     "start_time": "2019-10-31T23:36:27.180520Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import bs4 \n",
    "import requests\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # Higher resolution figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disclosure_year              0\n",
       "disclosure_date              0\n",
       "transaction_date             0\n",
       "owner                     4529\n",
       "ticker                       0\n",
       "asset_description            4\n",
       "type                         0\n",
       "amount                       0\n",
       "representative               0\n",
       "district                     0\n",
       "ptr_link                     0\n",
       "cap_gains_over_200_usd       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data/', 'all_transactions.csv')\n",
    "all_transactions = pd.read_csv(fp)\n",
    "all_transactions.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let us begin by finding all potential fake missingness and turning it into real missingness. It appears, after some rigorous analysis (looking at each series potential values), that the only fake missingness exists in the 'owner' and 'ticker' columns. We will now replace those values with NaNs. In summary:\n",
    "\n",
    "Missingness in data:\n",
    "- Owner column has fake missing ('--') and real missing\n",
    "- Ticker column has fake missing ('--')\n",
    "- Asset description column has real missing but only 4 so we can hand clean this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disclosure_year                                                        2021\n",
       "disclosure_date                                                  03/18/2021\n",
       "transaction_date                                                 2021-02-18\n",
       "owner                                                                   NaN\n",
       "ticker                                                                 URGO\n",
       "asset_description                                                       NaN\n",
       "type                                                               purchase\n",
       "amount                                                     $1,001 - $15,000\n",
       "representative                                              Hon. Brian Mast\n",
       "district                                                               FL18\n",
       "ptr_link                  https://disclosures-clerk.house.gov/public_dis...\n",
       "cap_gains_over_200_usd                                                False\n",
       "Name: 10538, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_transactions.iloc[732] #Replace NaN in a_d with Ball Corporation\n",
    "all_transactions.iloc[3262] #Replace NaN in a_d with CELO\n",
    "all_transactions.iloc[10537] #Replace NaN in a_d with URGO\n",
    "all_transactions.iloc[10538] #Replace NaN in a_d with URGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions.at[732, 'asset_description'] = 'Ball Corporation'\n",
    "all_transactions.at[3262, 'asset_description'] = 'CELO'\n",
    "all_transactions.at[10537, 'asset_description'] = 'URGO'\n",
    "all_transactions.at[10538, 'asset_description'] = 'URGO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our current strategy for tickers is to ignore the ticker and instead use the asset description wherever we can. The ticker is currently hypothesized to be NMAR after some brief exploration of some missing tickers: Missing dependent upon if the asset is listed on the NASDAQ. This can be further proven by understanding that the collection process populates the form according to NASDAQ tickers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell we sorted the transaction date values to find the smallest values from a string perspective, and discovered several anomalies. For these anomalies our intention is to hand clean the data and make sure that the date listed matches the date reported in the PDF sent in to Congress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069    0009-06-09\n",
       "9381    0021-06-22\n",
       "3496    0021-08-02\n",
       "9382    0201-06-22\n",
       "8662    2012-06-19\n",
       "3489    2018-09-08\n",
       "3488    2018-09-09\n",
       "9627    2018-12-27\n",
       "7875    2019-01-09\n",
       "7535    2019-01-09\n",
       "Name: transaction_date, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_transactions['transaction_date'].sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disclosure_year                                                        2021\n",
       "disclosure_date                                                  07/16/2021\n",
       "transaction_date                                                 0201-06-22\n",
       "owner                                                                   NaN\n",
       "ticker                                                                   KR\n",
       "asset_description                                            Kroger Company\n",
       "type                                                           sale_partial\n",
       "amount                                                     $1,001 - $15,000\n",
       "representative                                       Hon. James E Hon Banks\n",
       "district                                                               IN03\n",
       "ptr_link                  https://disclosures-clerk.house.gov/public_dis...\n",
       "cap_gains_over_200_usd                                                False\n",
       "Name: 9382, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_transactions.iloc[8662] #Correct transaction date is: 06/19/2020\n",
    "all_transactions.iloc[2069] #Correct transaction date is: 06/09/2021\n",
    "all_transactions.iloc[9381] #Correct transaction date is: 06/22/2021\n",
    "all_transactions.iloc[3496] #Correct transaction date is: 08/02/2021\n",
    "all_transactions.iloc[9382] #Correct transaction date is: 06/22/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions.at[8662, 'transaction_date'] = '2020-06-19'\n",
    "all_transactions.at[2069, 'transaction_date'] = '2021-06-09'\n",
    "all_transactions.at[9381, 'transaction_date'] = '2021-06-22'\n",
    "all_transactions.at[3496, 'transaction_date'] = '2021-08-02'\n",
    "all_transactions.at[9382, 'transaction_date'] = '2021-06-22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3489    2018-09-08\n",
       "3488    2018-09-09\n",
       "9627    2018-12-27\n",
       "7475    2019-01-09\n",
       "7535    2019-01-09\n",
       "7797    2019-01-09\n",
       "7469    2019-01-09\n",
       "7560    2019-01-09\n",
       "7420    2019-01-09\n",
       "7570    2019-01-09\n",
       "Name: transaction_date, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_transactions['transaction_date'].sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_w_nan = all_transactions.replace('--', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disclosure_year              0\n",
       "disclosure_date              0\n",
       "transaction_date             0\n",
       "owner                     5844\n",
       "ticker                    1023\n",
       "asset_description            0\n",
       "type                         0\n",
       "amount                       0\n",
       "representative               0\n",
       "district                     0\n",
       "ptr_link                     0\n",
       "cap_gains_over_200_usd       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_w_nan.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_w_nan['transaction_date'] = pd.to_datetime(transactions_w_nan['transaction_date'])\n",
    "transactions_w_nan['transaction_date'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_w_nan['disclosure_date'] = pd.to_datetime(transactions_w_nan['disclosure_date'])\n",
    "transactions_w_nan['disclosure_date'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to join our dataset with the parties for each district DURING THE TIME PERIOD OF EACH DISCLOSURE. After some exploration of the official roster on the house page, we discovered that some representatives in this dataset are no longer a a part of the house. Thus our only recourse is to scrape the historical list of house members provided on this webpage: https://www.congress.gov/members?pageSize=250&q=%7B%22chamber%22%3A%22House%22%2C%22congress%22%3A%5B%22116%22%2C117%5D%7D and match entries using the district name, and date.\n",
    "\n",
    "If possible during this process, we'd like to clean names as well. This is because during our initial exploration we discovered several naming inconsistencies. For an example see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hon. Neal Patrick MD, Facs Dunn',\n",
       "       'Hon. Neal Patrick MD, FACS Dunn',\n",
       "       'Hon. Neal Patrick Dunn MD, FACS'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_w_nan['representative'][transactions_w_nan['representative'].str.contains('Neal')].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not the only representative with multiple messy names, just the most obvious. So, let us scrape that webpage now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alabama': 'AL',\n",
       " 'Alaska': 'AK',\n",
       " 'Arizona': 'AZ',\n",
       " 'Arkansas': 'AR',\n",
       " 'California': 'CA',\n",
       " 'Colorado': 'CO',\n",
       " 'Connecticut': 'CT',\n",
       " 'Delaware': 'DE',\n",
       " 'Florida': 'FL',\n",
       " 'Georgia': 'GA',\n",
       " 'Hawaii': 'HI',\n",
       " 'Idaho': 'ID',\n",
       " 'Illinois': 'IL',\n",
       " 'Indiana': 'IN',\n",
       " 'Iowa': 'IA',\n",
       " 'Kansas': 'KS',\n",
       " 'Kentucky': 'KY',\n",
       " 'Louisiana': 'LA',\n",
       " 'Maine': 'ME',\n",
       " 'Maryland': 'MD',\n",
       " 'Massachusetts': 'MA',\n",
       " 'Michigan': 'MI',\n",
       " 'Minnesota': 'MN',\n",
       " 'Mississippi': 'MS',\n",
       " 'Missouri': 'MO',\n",
       " 'Montana': 'MT',\n",
       " 'Nebraska': 'NE',\n",
       " 'Nevada': 'NV',\n",
       " 'New Hampshire': 'NH',\n",
       " 'New Jersey': 'NJ',\n",
       " 'New Mexico': 'NM',\n",
       " 'New York': 'NY',\n",
       " 'North Carolina': 'NC',\n",
       " 'North Dakota': 'ND',\n",
       " 'Ohio': 'OH',\n",
       " 'Oklahoma': 'OK',\n",
       " 'Oregon': 'OR',\n",
       " 'Pennsylvania': 'PA',\n",
       " 'Rhode Island': 'RI',\n",
       " 'South Carolina': 'SC',\n",
       " 'South Dakota': 'SD',\n",
       " 'Tennessee': 'TN',\n",
       " 'Texas': 'TX',\n",
       " 'Utah': 'UT',\n",
       " 'Vermont': 'VT',\n",
       " 'Virginia': 'VA',\n",
       " 'Washington': 'WA',\n",
       " 'West Virginia': 'WV',\n",
       " 'Wisconsin': 'WI',\n",
       " 'Wyoming': 'WY',\n",
       " 'Territory Name': 'USPS Abbreviation',\n",
       " 'American Samoa': 'AS',\n",
       " 'District of Columbia': 'DC',\n",
       " 'Guam': 'GU',\n",
       " 'Northern Mariana Islands': 'MP',\n",
       " 'Puerto Rico': 'PR',\n",
       " 'Virgin Islands': 'VI'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site = requests.get('https://abbreviations.yourdictionary.com/articles/state-abbrev.html')\n",
    "site.status_code\n",
    "soup = bs4.BeautifulSoup(site.text, features = 'html.parser')\n",
    "abbr_dct = {name.find_all('td')[0].text: name.find_all('td')[1].text for name in soup.find_all('tr')[1:]}\n",
    "abbr_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alabama': 'AL',\n",
       " 'Alaska': 'AK',\n",
       " 'Arizona': 'AZ',\n",
       " 'Arkansas': 'AR',\n",
       " 'California': 'CA',\n",
       " 'Colorado': 'CO',\n",
       " 'Connecticut': 'CT',\n",
       " 'Delaware': 'DE',\n",
       " 'Florida': 'FL',\n",
       " 'Georgia': 'GA',\n",
       " 'Hawaii': 'HI',\n",
       " 'Idaho': 'ID',\n",
       " 'Illinois': 'IL',\n",
       " 'Indiana': 'IN',\n",
       " 'Iowa': 'IA',\n",
       " 'Kansas': 'KS',\n",
       " 'Kentucky': 'KY',\n",
       " 'Louisiana': 'LA',\n",
       " 'Maine': 'ME',\n",
       " 'Maryland': 'MD',\n",
       " 'Massachusetts': 'MA',\n",
       " 'Michigan': 'MI',\n",
       " 'Minnesota': 'MN',\n",
       " 'Mississippi': 'MS',\n",
       " 'Missouri': 'MO',\n",
       " 'Montana': 'MT',\n",
       " 'Nebraska': 'NE',\n",
       " 'Nevada': 'NV',\n",
       " 'New Hampshire': 'NH',\n",
       " 'New Jersey': 'NJ',\n",
       " 'New Mexico': 'NM',\n",
       " 'New York': 'NY',\n",
       " 'North Carolina': 'NC',\n",
       " 'North Dakota': 'ND',\n",
       " 'Ohio': 'OH',\n",
       " 'Oklahoma': 'OK',\n",
       " 'Oregon': 'OR',\n",
       " 'Pennsylvania': 'PA',\n",
       " 'Rhode Island': 'RI',\n",
       " 'South Carolina': 'SC',\n",
       " 'South Dakota': 'SD',\n",
       " 'Tennessee': 'TN',\n",
       " 'Texas': 'TX',\n",
       " 'Utah': 'UT',\n",
       " 'Vermont': 'VT',\n",
       " 'Virginia': 'VA',\n",
       " 'Washington': 'WA',\n",
       " 'West Virginia': 'WV',\n",
       " 'Wisconsin': 'WI',\n",
       " 'Wyoming': 'WY',\n",
       " 'Territory Name': 'USPS Abbreviation',\n",
       " 'American Samoa': 'AS',\n",
       " 'District of Columbia': 'DC',\n",
       " 'Guam': 'GU',\n",
       " 'Northern Mariana Islands': 'MP',\n",
       " 'Puerto Rico': 'PR',\n",
       " 'Virgin Islands': 'VI'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment of Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Test / Permutation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
